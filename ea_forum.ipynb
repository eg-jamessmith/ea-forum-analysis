{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSJBbeploeZjTiLBhFW9J3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eg-jamessmith/ea-forum-analysis/blob/main/ea_forum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collection Info From the EA Forum for Modelling and Experiments"
      ],
      "metadata": {
        "id": "gKIKVAGdzlI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NlrZ1sy2tLB7"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Posts from the EA Forum's AI Safety Frontpage"
      ],
      "metadata": {
        "id": "nerN_ROIzKGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "file_path = \"/content/drive/My Drive/coding_projects/ea-forum/ea-forum_posts.csv\"\n",
        "\n",
        "try:\n",
        "    df_existing = pd.read_csv(file_path)\n",
        "except FileNotFoundError:\n",
        "    df_existing = pd.DataFrame()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY2xb_AY0nGG",
        "outputId": "bf547ee6-c474-41a4-bfc4-3f2fc9fb22aa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the website\n",
        "URL = 'https://forum.effectivealtruism.org/topics/ai-safety?tab=posts'\n",
        "\n",
        "# Fetch the content of the website\n",
        "response = requests.get(URL)\n",
        "content = response.content\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "# Extract the posts and their links\n",
        "posts = soup.find_all('a', href=True, text=True)\n",
        "filtered_posts = [post for post in posts if \"/posts/\" in post['href']]\n",
        "post_details = [(post.get_text(), 'https://forum.effectivealtruism.org' + post['href']) for post in filtered_posts]\n",
        "\n",
        "# Convert the post details to a pandas DataFrame\n",
        "df_posts = pd.DataFrame(post_details, columns=[\"Title\", \"Link\"])\n",
        "\n",
        "# Display the DataFrame\n",
        "df_posts.sample(5).Link.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyWF59EqtUbO",
        "outputId": "c5888cf3-95d6-4b17-f076-c91e1fd095ff"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-275e9bd3c7a7>:12: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  posts = soup.find_all('a', href=True, text=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['https://forum.effectivealtruism.org/posts/y7pCAoghcNKhhufCS/ai-pause-governance-advocacy-might-be-net-negative',\n",
              "       'https://forum.effectivealtruism.org/posts/ggSXcuMzRaowDbKTz/possible-divergence-in-agi-risk-tolerance-between-selfish',\n",
              "       'https://forum.effectivealtruism.org/posts/6SvZPHAvhT5dtqefF/debate-series-should-we-push-for-a-pause-on-the-development',\n",
              "       'https://forum.effectivealtruism.org/posts/pNhc3jensyBY4Hz6u/panel-discussion-on-ai-consciousness-with-rob-long-and-jeff',\n",
              "       'https://forum.effectivealtruism.org/posts/cKbehBhq7NxTq3pck/a-case-study-of-regulation-done-well-canadian-biorisk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Authors and Content From Posts"
      ],
      "metadata": {
        "id": "AbmwwMDozXji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "authors = []\n",
        "post_text = []\n",
        "\n",
        "for _, row in df_posts.iterrows():\n",
        "\n",
        "  post_link = row['Link']\n",
        "\n",
        "  # Check if post_id is already in the existing data\n",
        "  if post_link not in df_existing[\"Link\"].values:\n",
        "\n",
        "    # Fetch the content of the website\n",
        "    response = requests.get(post_link)\n",
        "    content = response.content\n",
        "\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "    # Extract the author's name dynamically\n",
        "    author_tag = soup.find('a', class_='UsersNameDisplay-noColor', href=True)\n",
        "    if author_tag:\n",
        "        author_name = author_tag.get_text().strip()\n",
        "    else:\n",
        "        author_name = \"Not Found\"\n",
        "\n",
        "    # Extract the post's content (assuming the content is enclosed within <p> tags)\n",
        "    post_content = \"\\n\\n\".join([para.get_text().strip() for para in soup.find_all('p')])\n",
        "\n",
        "    authors.append(author_name)\n",
        "    post_text.append(post_content)\n",
        "\n",
        "# don't do anything if there's no new posts\n",
        "if len(authors) > 0:\n",
        "\n",
        "  df_posts['authors'] = authors\n",
        "  df_posts['post_text'] = post_text\n",
        "\n",
        "  # Assuming df_posts contains the new data you want to append\n",
        "  df_combined = pd.concat([df_existing, df_posts])\n",
        "  df_combined.to_csv(file_path, index=False)"
      ],
      "metadata": {
        "id": "QdWxPc4YtsrA"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}